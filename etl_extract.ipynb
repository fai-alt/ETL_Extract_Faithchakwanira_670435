{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689c8df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100 records of sales data in 'sales_transactions.csv'\n",
      "Sample data:\n",
      "   transaction_id  customer_id product_id       product_name     category  \\\n",
      "0           10000         1114       F606   Screen Protector  Accessories   \n",
      "1           10001         1758       F606   Screen Protector  Accessories   \n",
      "2           10002         1238       B202  Bluetooth Speaker  Electronics   \n",
      "3           10003         1603       D404         Phone Case  Accessories   \n",
      "4           10004         1284       C303        Smart Watch  Electronics   \n",
      "\n",
      "   quantity  unit_price  amount     transaction_date         last_updated  \\\n",
      "0         1       13.62   13.62  2025-05-01 18:12:35  2025-05-02 08:12:35   \n",
      "1         3       11.92   35.76  2025-05-13 18:12:35  2025-05-13 20:12:35   \n",
      "2         3       51.01  153.03  2025-05-21 18:12:35  2025-05-22 06:12:35   \n",
      "3         2       21.23   42.46  2025-04-16 18:12:35  2025-04-18 18:12:35   \n",
      "4         1      188.60  188.60  2025-06-03 18:12:35  2025-06-04 15:12:35   \n",
      "\n",
      "  payment_method region  \n",
      "0     Debit Card  North  \n",
      "1    Credit Card  North  \n",
      "2           Cash  South  \n",
      "3     Debit Card   West  \n",
      "4    Credit Card  North  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Generate 100 records (more than the required 50)\n",
    "num_records = 100\n",
    "\n",
    "# Product catalog\n",
    "products = {\n",
    "    'A101': {'name': 'Wireless Headphones', 'category': 'Electronics', 'base_price': 89.99},\n",
    "    'B202': {'name': 'Bluetooth Speaker', 'category': 'Electronics', 'base_price': 49.99},\n",
    "    'C303': {'name': 'Smart Watch', 'category': 'Electronics', 'base_price': 199.99},\n",
    "    'D404': {'name': 'Phone Case', 'category': 'Accessories', 'base_price': 19.99},\n",
    "    'E505': {'name': 'USB Cable', 'category': 'Accessories', 'base_price': 9.99},\n",
    "    'F606': {'name': 'Screen Protector', 'category': 'Accessories', 'base_price': 12.99}\n",
    "}\n",
    "\n",
    "# Customer regions\n",
    "regions = ['North', 'South', 'East', 'West']\n",
    "\n",
    "# Generate synthetic sales data\n",
    "data = []\n",
    "start_date = datetime.now() - timedelta(days=60)\n",
    "\n",
    "for i in range(num_records):\n",
    "    # Choose a random product\n",
    "    product_id = random.choice(list(products.keys()))\n",
    "    product = products[product_id]\n",
    "    \n",
    "    # Generate transaction details\n",
    "    transaction_id = 10000 + i\n",
    "    customer_id = random.randint(1000, 1999)\n",
    "    quantity = random.randint(1, 3)\n",
    "    \n",
    "    # Add some price variability\n",
    "    price_variation = random.uniform(0.9, 1.1)  # Â±10% variation\n",
    "    unit_price = round(product['base_price'] * price_variation, 2)\n",
    "    amount = round(unit_price * quantity, 2)\n",
    "    \n",
    "    # Generate timestamp (spread over last 60 days)\n",
    "    days_ago = random.randint(0, 60)\n",
    "    transaction_date = start_date + timedelta(days=days_ago)\n",
    "    \n",
    "    # Last updated is either transaction date or later (for returns/updates)\n",
    "    last_updated = transaction_date + timedelta(hours=random.randint(0, 48))\n",
    "    \n",
    "    # Add some payment methods\n",
    "    payment_method = random.choice(['Credit Card', 'Debit Card', 'PayPal', 'Cash'])\n",
    "    \n",
    "    # Add region\n",
    "    region = random.choice(regions)\n",
    "    \n",
    "    data.append({\n",
    "        'transaction_id': transaction_id,\n",
    "        'customer_id': customer_id,\n",
    "        'product_id': product_id,\n",
    "        'product_name': product['name'],\n",
    "        'category': product['category'],\n",
    "        'quantity': quantity,\n",
    "        'unit_price': unit_price,\n",
    "        'amount': amount,\n",
    "        'transaction_date': transaction_date.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'last_updated': last_updated.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'payment_method': payment_method,\n",
    "        'region': region\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('custom_data.csv', index=False)\n",
    "\n",
    "print(f\"Generated {len(df)} records of sales data in 'sales_transactions.csv'\")\n",
    "print(\"Sample data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec06eb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Section 1: Full Extraction ---\n",
      "Total rows: 100\n",
      "Total columns: 12\n",
      "Sample data (first 5 rows):\n",
      "   transaction_id  customer_id product_id       product_name     category  \\\n",
      "0           10000         1114       F606   Screen Protector  Accessories   \n",
      "1           10001         1758       F606   Screen Protector  Accessories   \n",
      "2           10002         1238       B202  Bluetooth Speaker  Electronics   \n",
      "3           10003         1603       D404         Phone Case  Accessories   \n",
      "4           10004         1284       C303        Smart Watch  Electronics   \n",
      "\n",
      "   quantity  unit_price  amount     transaction_date         last_updated  \\\n",
      "0         1       13.62   13.62  2025-05-01 18:12:35  2025-05-02 08:12:35   \n",
      "1         3       11.92   35.76  2025-05-13 18:12:35  2025-05-13 20:12:35   \n",
      "2         3       51.01  153.03  2025-05-21 18:12:35  2025-05-22 06:12:35   \n",
      "3         2       21.23   42.46  2025-04-16 18:12:35  2025-04-18 18:12:35   \n",
      "4         1      188.60  188.60  2025-06-03 18:12:35  2025-06-04 15:12:35   \n",
      "\n",
      "  payment_method region  \n",
      "0     Debit Card  North  \n",
      "1    Credit Card  North  \n",
      "2           Cash  South  \n",
      "3     Debit Card   West  \n",
      "4    Credit Card  North  \n",
      "Extracted 100 rows fully.\n",
      "\n",
      "--- Section 2: Incremental Extraction ---\n",
      "Last extraction timestamp: 2025-06-10 20:41:33.474690\n",
      "Simulated adding 3 new records to custom_data.csv\n",
      "Extracted 12 rows incrementally since last check.\n",
      "Sample of incrementally extracted data:\n",
      "    transaction_id  customer_id product_id         product_name     category  \\\n",
      "9            10009         1214       C303          Smart Watch  Electronics   \n",
      "21           10021         1019       D404           Phone Case  Accessories   \n",
      "25           10025         1687       D404           Phone Case  Accessories   \n",
      "38           10038         1051       A101  Wireless Headphones  Electronics   \n",
      "41           10041         1597       F606     Screen Protector  Accessories   \n",
      "\n",
      "    quantity  unit_price  amount     transaction_date        last_updated  \\\n",
      "9          3      190.67  572.01  2025-06-14 18:12:35 2025-06-16 13:12:35   \n",
      "21         1       21.71   21.71  2025-06-11 18:12:35 2025-06-12 13:12:35   \n",
      "25         3       19.48   58.44  2025-06-12 18:12:35 2025-06-14 03:12:35   \n",
      "38         3       89.57  268.71  2025-06-13 18:12:35 2025-06-15 03:12:35   \n",
      "41         3       13.05   39.15  2025-06-14 18:12:35 2025-06-15 10:12:35   \n",
      "\n",
      "   payment_method region  \n",
      "9     Credit Card  South  \n",
      "21     Debit Card  North  \n",
      "25           Cash  North  \n",
      "38     Debit Card  North  \n",
      "41     Debit Card   East  \n",
      "\n",
      "--- Section 3: Save New Timestamp ---\n",
      "Updated last_extraction.txt with new timestamp: 2025-06-15 18:12:43.438477\n",
      "\n",
      "ETL process complete!\n"
     ]
    }
   ],
   "source": [
    "# Section 1: Full Extraction\n",
    "\n",
    "print(\"\\n--- Section 1: Full Extraction ---\")\n",
    "\n",
    "# Load the entire dataset\n",
    "full_df = pd.read_csv('custom_data.csv')\n",
    "\n",
    "# Display basic stats\n",
    "print(f\"Total rows: {full_df.shape[0]}\")\n",
    "print(f\"Total columns: {full_df.shape[1]}\")\n",
    "print(\"Sample data (first 5 rows):\")\n",
    "print(full_df.head())\n",
    "\n",
    "# Print a message\n",
    "print(f\"Extracted {full_df.shape[0]} rows fully.\")\n",
    "\n",
    "\n",
    "# Section 2: Incremental Extraction\n",
    "\n",
    "print(\"\\n--- Section 2: Incremental Extraction ---\")\n",
    "\n",
    "last_extraction_file = 'last_extraction.txt'\n",
    "\n",
    "def get_last_extraction_timestamp():\n",
    "    try:\n",
    "        with open(last_extraction_file, 'r') as f:\n",
    "            timestamp_str = f.read().strip()\n",
    "            if timestamp_str:\n",
    "                # Handle ISO format timestamps\n",
    "                return datetime.fromisoformat(timestamp_str)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    return datetime.min # Return a very old date if file doesn't exist or is empty\n",
    "def save_last_extraction_timestamp(timestamp):\n",
    "    with open(last_extraction_file, 'w') as f:\n",
    "        f.write(timestamp.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "last_extracted_time = get_last_extraction_timestamp()\n",
    "print(f\"Last extraction timestamp: {last_extracted_time}\")\n",
    "\n",
    "# Simulate new data generation for incremental extraction\n",
    "# For demonstration, let's add a few new records or update existing ones\n",
    "\n",
    "# Read existing data (if any changes were made directly to custom_data.csv outside the notebook)\n",
    "existing_df = pd.read_csv('custom_data.csv')\n",
    "\n",
    "# Generate a few new records for incremental extraction simulation\n",
    "new_records_data = []\n",
    "current_time = datetime.now() + timedelta(hours=1) # Simulate current time is later\n",
    "\n",
    "# Add some new records (e.g., 3 new transactions)\n",
    "for i in range(3):\n",
    "    product_id = random.choice(list(products.keys()))\n",
    "    product = products[product_id]\n",
    "    \n",
    "    new_records_data.append({\n",
    "        'transaction_id': existing_df['transaction_id'].max() + 1 + i,\n",
    "        'customer_id': random.randint(2000, 2999),\n",
    "        'product_id': product_id,\n",
    "        'product_name': product['name'],\n",
    "        'category': product['category'],\n",
    "        'quantity': random.randint(1, 3),\n",
    "        'unit_price': round(product['base_price'] * random.uniform(0.9, 1.1), 2),\n",
    "        'amount': round(product['base_price'] * random.uniform(0.9, 1.1) * random.randint(1, 3), 2),\n",
    "        'transaction_date': current_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'last_updated': current_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'payment_method': random.choice(['Credit Card', 'Debit Card']),\n",
    "        'region': random.choice(regions)\n",
    "    })\n",
    "\n",
    "new_df = pd.DataFrame(new_records_data)\n",
    "\n",
    "# Append new data to the existing data and save to custom_data.csv\n",
    "# This simulates new data arriving in the source system\n",
    "updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "updated_df.to_csv('custom_data.csv', index=False)\n",
    "\n",
    "print(f\"Simulated adding {len(new_df)} new records to custom_data.csv\")\n",
    "\n",
    "# Extract only new or updated records since last_extracted_time\n",
    "# Reload the dataset to get the latest changes including simulated new data\n",
    "data_for_incremental = pd.read_csv('custom_data.csv')\n",
    "data_for_incremental['last_updated'] = pd.to_datetime(data_for_incremental['last_updated'])\n",
    "\n",
    "incremental_df = data_for_incremental[data_for_incremental['last_updated'] > last_extracted_time]\n",
    "\n",
    "print(f\"Extracted {incremental_df.shape[0]} rows incrementally since last check.\")\n",
    "print(\"Sample of incrementally extracted data:\")\n",
    "print(incremental_df.head())\n",
    "\n",
    "# Section 3: Save New Timestamp\n",
    "\n",
    "print(\"\\n--- Section 3: Save New Timestamp ---\")\n",
    "\n",
    "# After successful incremental extraction, update the last_extraction.txt\n",
    "# Use the current time as the new last extraction timestamp\n",
    "new_last_extraction_time = datetime.now()\n",
    "save_last_extraction_timestamp(new_last_extraction_time)\n",
    "\n",
    "print(f\"Updated last_extraction.txt with new timestamp: {new_last_extraction_time}\")\n",
    "\n",
    "print(\"\\nETL process complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a5170b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Section 4: Transform Full Data ---\n",
      "Transformation 1: Handled missing values.\n",
      "Transformation 2: Added 'total_price' column.\n",
      "Transformation 3: Converted date columns to datetime objects.\n",
      "Sample of transformed full data (first 5 rows):\n",
      "   transaction_id  customer_id product_id       product_name     category  \\\n",
      "0           10000         1114       F606   Screen Protector  Accessories   \n",
      "1           10001         1758       F606   Screen Protector  Accessories   \n",
      "2           10002         1238       B202  Bluetooth Speaker  Electronics   \n",
      "3           10003         1603       D404         Phone Case  Accessories   \n",
      "4           10004         1284       C303        Smart Watch  Electronics   \n",
      "\n",
      "   quantity  unit_price  amount    transaction_date        last_updated  \\\n",
      "0         1       13.62   13.62 2025-05-01 18:12:35 2025-05-02 08:12:35   \n",
      "1         3       11.92   35.76 2025-05-13 18:12:35 2025-05-13 20:12:35   \n",
      "2         3       51.01  153.03 2025-05-21 18:12:35 2025-05-22 06:12:35   \n",
      "3         2       21.23   42.46 2025-04-16 18:12:35 2025-04-18 18:12:35   \n",
      "4         1      188.60  188.60 2025-06-03 18:12:35 2025-06-04 15:12:35   \n",
      "\n",
      "  payment_method region  total_price  \n",
      "0     Debit Card  North        13.62  \n",
      "1    Credit Card  North        35.76  \n",
      "2           Cash  South       153.03  \n",
      "3     Debit Card   West        42.46  \n",
      "4    Credit Card  North       188.60  \n",
      "Saved transformed full data to 'transformed_full.csv' with 100 rows.\n",
      "\n",
      "--- Section 5: Transform Incremental Data ---\n",
      "Transformation 1: Handled missing values for incremental data.\n",
      "Transformation 2: Added 'total_price' column for incremental data.\n",
      "Transformation 3: Converted date columns to datetime objects for incremental data.\n",
      "Sample of transformed incremental data (first 5 rows):\n",
      "    transaction_id  customer_id product_id         product_name     category  \\\n",
      "9            10009         1214       C303          Smart Watch  Electronics   \n",
      "21           10021         1019       D404           Phone Case  Accessories   \n",
      "25           10025         1687       D404           Phone Case  Accessories   \n",
      "38           10038         1051       A101  Wireless Headphones  Electronics   \n",
      "41           10041         1597       F606     Screen Protector  Accessories   \n",
      "\n",
      "    quantity  unit_price  amount    transaction_date        last_updated  \\\n",
      "9          3      190.67  572.01 2025-06-14 18:12:35 2025-06-16 13:12:35   \n",
      "21         1       21.71   21.71 2025-06-11 18:12:35 2025-06-12 13:12:35   \n",
      "25         3       19.48   58.44 2025-06-12 18:12:35 2025-06-14 03:12:35   \n",
      "38         3       89.57  268.71 2025-06-13 18:12:35 2025-06-15 03:12:35   \n",
      "41         3       13.05   39.15 2025-06-14 18:12:35 2025-06-15 10:12:35   \n",
      "\n",
      "   payment_method region  total_price  \n",
      "9     Credit Card  South       572.01  \n",
      "21     Debit Card  North        21.71  \n",
      "25           Cash  North        58.44  \n",
      "38     Debit Card  North       268.71  \n",
      "41     Debit Card   East        39.15  \n",
      "Saved transformed incremental data to 'transformed_incremental.csv' with 12 rows.\n",
      "\n",
      "ETL process complete!\n"
     ]
    }
   ],
   "source": [
    "# Section 4: Transform Full Data\n",
    "\n",
    "print(\"\\n--- Section 4: Transform Full Data ---\")\n",
    "\n",
    "# Make a copy to avoid SettingWithCopyWarning\n",
    "transformed_full_df = full_df.copy()\n",
    "\n",
    "# Transformation 1: Handle missing values (Example: fill numerical NaNs with mean, categorical with 'Unknown')\n",
    "# Numerical columns to fill with mean\n",
    "numerical_cols = ['quantity', 'unit_price', 'amount']\n",
    "for col in numerical_cols:\n",
    "    if transformed_full_df[col].isnull().any():\n",
    "        transformed_full_df[col].fillna(transformed_full_df[col].mean(), inplace=True)\n",
    "\n",
    "# Categorical columns to fill with 'Unknown'\n",
    "categorical_cols = ['product_name', 'category', 'payment_method', 'region']\n",
    "for col in categorical_cols:\n",
    "    if transformed_full_df[col].isnull().any():\n",
    "        transformed_full_df[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "print(\"Transformation 1: Handled missing values.\")\n",
    "\n",
    "# Transformation 2: Enrichment - Add 'total_price' column\n",
    "transformed_full_df['total_price'] = transformed_full_df['quantity'] * transformed_full_df['unit_price']\n",
    "print(\"Transformation 2: Added 'total_price' column.\")\n",
    "\n",
    "# Transformation 3: Structural - Convert date columns to datetime objects\n",
    "transformed_full_df['transaction_date'] = pd.to_datetime(transformed_full_df['transaction_date'])\n",
    "transformed_full_df['last_updated'] = pd.to_datetime(transformed_full_df['last_updated'])\n",
    "print(\"Transformation 3: Converted date columns to datetime objects.\")\n",
    "\n",
    "print(\"Sample of transformed full data (first 5 rows):\")\n",
    "print(transformed_full_df.head())\n",
    "\n",
    "# Save transformed full data\n",
    "transformed_full_df.to_csv('transformed_full.csv', index=False)\n",
    "print(f\"Saved transformed full data to 'transformed_full.csv' with {transformed_full_df.shape[0]} rows.\")\n",
    "\n",
    "\n",
    "# Section 5: Transform Incremental Data\n",
    "\n",
    "print(\"\\n--- Section 5: Transform Incremental Data ---\")\n",
    "\n",
    "# Make a copy to avoid SettingWithCopyWarning\n",
    "transformed_incremental_df = incremental_df.copy()\n",
    "\n",
    "# Apply the same transformations as Full Data to ensure consistency\n",
    "\n",
    "# Transformation 1: Handle missing values\n",
    "for col in numerical_cols: # Reusing numerical_cols from full transformation\n",
    "    if transformed_incremental_df[col].isnull().any():\n",
    "        # Here, we'll recompute for simplicity in a self-contained incremental transform\n",
    "        transformed_incremental_df[col].fillna(transformed_incremental_df[col].mean(), inplace=True)\n",
    "\n",
    "for col in categorical_cols: # Reusing categorical_cols from full transformation\n",
    "    if transformed_incremental_df[col].isnull().any():\n",
    "        transformed_incremental_df[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "print(\"Transformation 1: Handled missing values for incremental data.\")\n",
    "\n",
    "# Transformation 2: Enrichment - Add 'total_price' column\n",
    "transformed_incremental_df['total_price'] = transformed_incremental_df['quantity'] * transformed_incremental_df['unit_price']\n",
    "print(\"Transformation 2: Added 'total_price' column for incremental data.\")\n",
    "\n",
    "# Transformation 3: Structural - Convert date columns to datetime objects\n",
    "# The 'last_updated' was already converted during incremental extraction, but re-confirm for 'transaction_date'\n",
    "transformed_incremental_df['transaction_date'] = pd.to_datetime(transformed_incremental_df['transaction_date'])\n",
    "transformed_incremental_df['last_updated'] = pd.to_datetime(transformed_incremental_df['last_updated'])\n",
    "print(\"Transformation 3: Converted date columns to datetime objects for incremental data.\")\n",
    "\n",
    "print(\"Sample of transformed incremental data (first 5 rows):\")\n",
    "print(transformed_incremental_df.head())\n",
    "\n",
    "# Save transformed incremental data\n",
    "transformed_incremental_df.to_csv('transformed_incremental.csv', index=False)\n",
    "print(f\"Saved transformed incremental data to 'transformed_incremental.csv' with {transformed_incremental_df.shape[0]} rows.\")\n",
    "\n",
    "print(\"\\nETL process complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
